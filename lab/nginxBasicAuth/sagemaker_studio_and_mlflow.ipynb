{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Scikit-Learn model in SageMaker and track with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLflowAPIendpoint = \"https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "The main objective of this notebook is to show how you can integrate Amazon SageMaker and MLFlow and MLFlow with SageMaker Experiments.\n",
    "\n",
    "## Pre-Requisites\n",
    "\n",
    "In order to run successfully this notebook, you must have prepared the infrastructure using CDK, which setups up for you the MLFlow server in an isolated VPC. When running this example in the SageMaker Notebook instance provisioned via CDK, you need to have access to the URI of the MLFlow server we will use for tracking purposes. In our case, this corresponds to the `HTTP API Gateway` endpoint that exposes our MLFlow server reacheable via a `PrivateLink` and have a SageMaker execution role with permissions to access the secret in `Amazon SecretsManager` from where we retrieve the username and password to interact with the MLFlow server.\n",
    "\n",
    "This notebook runs on SageMaker Studio using the `Base Python 2.0` image on a `Python 3` kernel.\n",
    "\n",
    "## The Machine Learning Problem\n",
    "\n",
    "In this example, we will solve a regression problem which aims to answer the question: \"what is the expected price of a house in the California area?\". The target variable is the house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    "## Install required and/or update libraries\n",
    "\n",
    "At the time of writing, we have used the `sagemaker` SDK version 2. The MLFlow SDK library used is the one corresponding to our MLFlow server version, i.e., `2.7.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n py38 python=3.8 anaconda -y && activate py38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.198.1)\n",
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.10/site-packages (0.1.45)\n",
      "Collecting scikit-learn==1.3.1\n",
      "  Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: mlflow==2.7.1 in /opt/conda/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.3.1) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.3.1) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.3.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.3.1) (3.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (2.2.1)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (0.18.0)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (3.1.41)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (6.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (4.21.12)\n",
      "Requirement already satisfied: pytz<2024 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (2023.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (23.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (6.10.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (0.4.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (1.13.1)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (6.1.3)\n",
      "Requirement already satisfied: Flask<3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (2.3.3)\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (2.1.4)\n",
      "Requirement already satisfied: querystring-parser<2 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (1.4.49)\n",
      "Requirement already satisfied: pyarrow<14,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (12.0.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (3.5.2)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (3.8.2)\n",
      "Requirement already satisfied: gunicorn<22 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (21.2.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow==2.7.1) (3.1.3)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.29.6 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.34.62)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.7.1) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.7.1) (4.5.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.62 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.29.6->sagemaker) (1.34.62)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.29.6->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.29.6->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (2.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in /opt/conda/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (1.26.18)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow==2.7.1) (1.7.0)\n",
      "Requirement already satisfied: Werkzeug>=2.3.7 in /opt/conda/lib/python3.10/site-packages (from Flask<3->mlflow==2.7.1) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3->mlflow==2.7.1) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3->mlflow==2.7.1) (1.7.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=2.1.0->mlflow==2.7.1) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.7.1) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.7.1) (2.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.7.1) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow==2.7.1) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.7.1) (3.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.20.0)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.7.1) (5.0.0)\n",
      "Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n",
      "Successfully installed scikit-learn-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install sagemaker sagemaker-experiments scikit-learn==1.3.1 mlflow==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.python.org/simple\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.34.62)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.62 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.34.62)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.62->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.62->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.62->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --extra-index-url https://pypi.python.org/simple boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the notebook instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/using-identity-based-policies.html) for more details on creating these.  Note, if a role not associated with the current notebook instance, or more than one role is required for training and/or hosting, please replace `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n",
    "- The tracking URI where the MLFlow server runs\n",
    "- The experiment name as the logical entity to keep our tests grouped and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "SageMaker role: SageMakerStudioUserStack-sagemakerexecutionrole002C-8wx1ROpxQjMH\n",
      "bucket: sagemaker-us-east-1-664947382407\n",
      "Account: 664947382407\n",
      "Using AWS Region: us-east-1\n",
      "MLflow server URI: https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\n",
      "MLFLOW_SECRET_NAME: mlflow-server-credentials\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import boto3\n",
    "\n",
    "## SageMaker and SKlearn libraries\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, HyperparameterTuner\n",
    "\n",
    "## SKLearn libraries\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## MLFlow libraries\n",
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "import mlflow.sagemaker\n",
    "\n",
    "cloudformation_client = boto3.client('cloudformation')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "region = sess.boto_region_name\n",
    "account = role.split(\"::\")[1].split(\":\")[0]\n",
    "tracking_uri = cloudformation_client.describe_stacks(StackName='HttpGatewayStack')['Stacks'][0]['Outputs'][0]['OutputValue']\n",
    "\n",
    "mlflow_secret_name = \"mlflow-server-credentials\"\n",
    "experiment_name = 'DEMO-sagemaker-mlflow'\n",
    "model_name = 'california-housing-model'\n",
    "\n",
    "print('SageMaker role: {}'.format(role.split(\"/\")[-1]))\n",
    "print('bucket: {}'.format(bucket))\n",
    "print('Account: {}'.format(account))\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "print(\"MLflow server URI: {}\".format(tracking_uri))\n",
    "print(\"MLFLOW_SECRET_NAME: {}\".format(mlflow_secret_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We load the dataset from sklearn, then split the data in training and testing datasets, where we allocate 75% of the data to the training dataset, and the remaining 25% to the traning dataset.\n",
    "\n",
    "The variable `target` is what we intend to estimate, which represents the value of a house, expressed in hundreds of thousands of dollars ($100,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the California housing dataset \n",
    "data = fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=42)\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX['target'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save a copy of the data locally, as well as in S3. The data stored in S3 will be used SageMaker to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data locally\n",
    "trainX.to_csv('california_train.csv', index=False)\n",
    "testX.to_csv('california_test.csv', index=False)\n",
    "\n",
    "# save the data to S3.\n",
    "train_path = sess.upload_data(path='california_train.csv', bucket=bucket, key_prefix='sagemaker/sklearncontainer')\n",
    "test_path = sess.upload_data(path='california_test.csv', bucket=bucket, key_prefix='sagemaker/sklearncontainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup SageMaker Experiments\n",
    "\n",
    "SageMaker Experiments is an AWS service for tracking machine learning Experiments. The SageMaker Experiments Python SDK is a high-level interface to this service that helps you track Experiment information using Python.\n",
    "\n",
    "Conceptually, these are the following entities within `SageMaker Experiments`:\n",
    "\n",
    "* Experiment: A collection of related Trials. Add Trials to an Experiment that you wish to compare together.\n",
    "* Trial: A description of a multi-step machine learning workflow. Each step in the workflow is described by a TrialComponent.\n",
    "* TrialComponent: A description of a single step in a machine learning workflow.\n",
    "* Tracker: A Python context-manager for logging information about a single TrialComponent.\n",
    "\n",
    "When running jobs (both training and processing ones) in the SageMaker managed infrastructure, SageMaker creates automatically a <i>TrialComponent</i>. <i>TrialComponents</i> includes by default jobs metadata and lineage information about the input and output data, models artifacts and metrics (for training jobs), and within your training script these data can be further enriched.\n",
    "\n",
    "We want to show how you can easily enable a two-way interaction between MLflow and SageMaker Experiments.\n",
    "\n",
    "Let us first create an `Experiment` and a `Trial`. These two entities are used to keep your experimentation organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new experiment created\n",
      "new trial created\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    my_experiment = Experiment.load(experiment_name=experiment_name)\n",
    "    print(\"existing experiment loaded\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_experiment = Experiment.create(\n",
    "            experiment_name = experiment_name,\n",
    "            description = \"MLFlow and SageMaker integration\"\n",
    "        )\n",
    "        print(\"new experiment created\")\n",
    "    else:\n",
    "        print(f\"Unexpected {ex}=, {type(ex)}\")\n",
    "        print(\"Dont go forward!\")\n",
    "        raise\n",
    "\n",
    "trial_name = \"trial-v1\"\n",
    "\n",
    "try:\n",
    "    my_first_trial = Trial.load(trial_name=trial_name)\n",
    "    print(\"existing trial loaded\")\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        my_first_trial = Trial.create(\n",
    "            experiment_name=experiment_name,\n",
    "            trial_name=trial_name,\n",
    "        )\n",
    "        print(\"new trial created\")\n",
    "    else:\n",
    "        print(f\"Unexpected {ex}=, {type(ex)}\")\n",
    "        print(\"Dont go forward!\")\n",
    "        raise\n",
    "\n",
    "create_date = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "experiment_config = {\n",
    "    \"ExperimentName\": experiment_name,\n",
    "    \"TrialName\": trial_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For this example, we use the `SKlearn` framework in script mode with SageMaker. Let us explore in more details the different components we need to define.\n",
    "\n",
    "### Traning script and SageMaker environment\n",
    "\n",
    "The `./source_dir/train.py` script provides all the code we need for training a SageMaker model. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_CHANNEL_TRAIN`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "* `SM_CHANNEL_TEST`: A string representing the path to the directory containing data in the 'testing' channel.\n",
    "\n",
    "\n",
    "For more information about training environment variables, please visit \n",
    "[SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md).\n",
    "\n",
    "We want to highlight in particular `SM_TRAINING_ENV` since it provides all the training information as a JSON-encoded dictionary (see [here](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md#sm_training_env) for more details).\n",
    "\n",
    "#### Hyperparmeters\n",
    "\n",
    "We are using the `RandomForestRegressor` algorithm from the SKlearn framework. For the purpose of this exercise, we are only using a subset of hyperparameters supported by this algorithm, i.e. `n-estimators` and `min-samples-leaf`\n",
    "\n",
    "If you would like to know more the different hyperparmeters for this algorithm, please refer to the [`RandomForestRegressor` official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "Furthermore, it is important to note that for the purpose of this excercise, we are essentially omitting completely the feature engineering step, which is an essential step in any machine learning problem.\n",
    "\n",
    "#### MLFlow interaction\n",
    "\n",
    "To interact with the MLFlow server, we use the mlflow SDK, which allows us to set the tracking URI and the experiment name. One this initial setup is completed, we can store the parameters used (`mlflow.log_params(params)`), the model that is generated (`mlflow.sklearn.log_model(model, \"model\")`) with its associated metrics (`mlflow.log_metric(f'AE-at-{str(q)}th-percentile', np.percentile(a=abs_err, q=q))`).\n",
    "\n",
    "TODO: explain the `mlflow.autolog()` and the <i>System Tags</i> (add link) and how to overwrite them to have the right reference in SageMaker\n",
    "\n",
    "#### SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# SPDX-License-Identifier: MIT-0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mensemble\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomForestRegressor\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlflow\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmlflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtracking\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MlflowClient\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msmexperiments\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtracker\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Tracker\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logging.basicConfig(level=logging.INFO)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mretrieve_credentials\u001b[39;49;00m(region_name, secret_name):\u001b[37m\u001b[39;49;00m\n",
      "    session = boto3.session.Session()\u001b[37m\u001b[39;49;00m\n",
      "    client = session.client(\u001b[37m\u001b[39;49;00m\n",
      "        service_name=\u001b[33m'\u001b[39;49;00m\u001b[33msecretsmanager\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        region_name=region_name\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    kwarg = {\u001b[33m'\u001b[39;49;00m\u001b[33mSecretId\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: secret_name}\u001b[37m\u001b[39;49;00m\n",
      "    secret = client.get_secret_value(**kwarg)\u001b[37m\u001b[39;49;00m\n",
      "    credentials = {}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    credentials[\u001b[33m'\u001b[39;49;00m\u001b[33musername\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = json.loads(secret[\u001b[33m'\u001b[39;49;00m\u001b[33mSecretString\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])[\u001b[33m'\u001b[39;49;00m\u001b[33musername\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    credentials[\u001b[33m'\u001b[39;49;00m\u001b[33mpassword\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = json.loads(secret[\u001b[33m'\u001b[39;49;00m\u001b[33mSecretString\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])[\u001b[33m'\u001b[39;49;00m\u001b[33mpassword\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m credentials\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprint_auto_logged_info\u001b[39;49;00m(r):\u001b[37m\u001b[39;49;00m\n",
      "    tags = {k: v \u001b[34mfor\u001b[39;49;00m k, v \u001b[35min\u001b[39;49;00m r.data.tags.items()}\u001b[37m\u001b[39;49;00m\n",
      "    artifacts = [f.path \u001b[34mfor\u001b[39;49;00m f \u001b[35min\u001b[39;49;00m MlflowClient().list_artifacts(r.info.run_id, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mrun_id: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(r.info.run_id))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33martifacts: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(artifacts))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(r.data.params))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmetrics: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(r.data.metrics))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#print(\"tags: {}\".format(tags))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m ==\u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# MLflow related parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--tracking_uri\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--experiment_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--region\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mus-west-2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--secret_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# to simplify the demo we don't use all sklearn RandomForest hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n-estimators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--min-samples-leaf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train-file\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mcalifornia_train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-file\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mcalifornia_test.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--user\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)  \u001b[37m# we ask user to explicitly name features\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--target\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m) \u001b[37m# we ask user to explicitly name the target\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mreading data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\u001b[37m\u001b[39;49;00m\n",
      "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mbuilding training and testing datasets\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    X_train = train_df[args.features.split()]\u001b[37m\u001b[39;49;00m\n",
      "    X_test = test_df[args.features.split()]\u001b[37m\u001b[39;49;00m\n",
      "    y_train = train_df[args.target]\u001b[37m\u001b[39;49;00m\n",
      "    y_test = test_df[args.target]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# sets the header Authentication: Basic <credentials>\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    credentials = retrieve_credentials(args.region, args.secret_name)\u001b[37m\u001b[39;49;00m\n",
      "    os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mMLFLOW_TRACKING_USERNAME\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = credentials[\u001b[33m'\u001b[39;49;00m\u001b[33musername\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mMLFLOW_TRACKING_PASSWORD\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = credentials[\u001b[33m'\u001b[39;49;00m\u001b[33mpassword\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# set remote mlflow server\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlflow.set_tracking_uri(args.tracking_uri)\u001b[37m\u001b[39;49;00m\n",
      "    experiment = mlflow.set_experiment(args.experiment_name)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    mlflow.autolog()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m mlflow.start_run() \u001b[34mas\u001b[39;49;00m run:\u001b[37m\u001b[39;49;00m\n",
      "        params = {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn-estimators\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_estimators,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mmin-samples-leaf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.min_samples_leaf,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mfeatures\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.features\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.log_params(params)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# TRAIN\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mtraining model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        model = RandomForestRegressor(\u001b[37m\u001b[39;49;00m\n",
      "            n_estimators=args.n_estimators,\u001b[37m\u001b[39;49;00m\n",
      "            min_samples_leaf=args.min_samples_leaf,\u001b[37m\u001b[39;49;00m\n",
      "            n_jobs=-\u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        model.fit(X_train, y_train)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# ABS ERROR AND LOG COUPLE PERF METRICS\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mevaluating model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        abs_err = np.abs(model.predict(X_test) - y_test)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m q \u001b[35min\u001b[39;49;00m [\u001b[34m10\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m, \u001b[34m90\u001b[39;49;00m]:\u001b[37m\u001b[39;49;00m\n",
      "            logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mAE-at-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mq\u001b[33m}\u001b[39;49;00m\u001b[33mth-percentile: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.percentile(a=abs_err,\u001b[37m \u001b[39;49;00mq=q)\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            mlflow.log_metric(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mAE-at-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mstr\u001b[39;49;00m(q)\u001b[33m}\u001b[39;49;00m\u001b[33mth-percentile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, np.percentile(a=abs_err, q=q))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# SAVE MODEL\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33msaving model in MLflow\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.sklearn.log_model(model, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        sm_data = json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_TRAINING_ENV\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "        job_name = sm_data[\u001b[33m'\u001b[39;49;00m\u001b[33mjob_name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Overwrite system tags\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.set_tags(\u001b[37m\u001b[39;49;00m\n",
      "            {\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmlflow.source.name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.region\u001b[33m}\u001b[39;49;00m\u001b[33m.console.aws.amazon.com/sagemaker/home?region=\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.region\u001b[33m}\u001b[39;49;00m\u001b[33m#/jobs/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mjob_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmlflow.source.type\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mJOB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmlflow.user\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.user\u001b[37m\u001b[39;49;00m\n",
      "            }\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Shovel all SageMaker related data into mlflow\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.set_tags(sm_data)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    run_id = run.info.run_id\u001b[37m\u001b[39;49;00m\n",
      "    experiment_id = experiment.experiment_id\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    r = mlflow.get_run(run_id=run_id)\u001b[37m\u001b[39;49;00m\n",
      "    print_auto_logged_info(r)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    artifacts = [f.path \u001b[34mfor\u001b[39;49;00m f \u001b[35min\u001b[39;49;00m MlflowClient().list_artifacts(r.info.run_id, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    tracker_parameters = {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mrun_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: run_id,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mexperiment_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: experiment_id,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mmlflow-run-url\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.tracking_uri\u001b[33m}\u001b[39;49;00m\u001b[33m/#/experiments/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mexperiment_id\u001b[33m}\u001b[39;49;00m\u001b[33m/runs/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrun_id\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m Tracker.load() \u001b[34mas\u001b[39;49;00m tracker:\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_parameters(tracker_parameters)\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_parameters(r.data.params)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m metric_name, value \u001b[35min\u001b[39;49;00m r.data.metrics.items():\u001b[37m\u001b[39;49;00m\n",
      "                tracker.log_metric(metric_name=metric_name, value=value)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m artifact \u001b[35min\u001b[39;49;00m artifacts:\u001b[37m\u001b[39;49;00m\n",
      "                tracker.log_output(name=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMLFlow.\u001b[39;49;00m\u001b[33m{\u001b[39;49;00martifact\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mr.info.artifact_uri\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00martifact\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# Nullify default SageMaker.ModelArtifact\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_output(name=\u001b[33m\"\u001b[39;49;00m\u001b[33mSageMaker.ModelArtifact\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[33m\"\u001b[39;49;00m\u001b[33mNA\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoaded existing tracker\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mexcept\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCould not load tracker (likely running in local mode). Create a new one\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        create_date = time.strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm-\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM-\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        tracker_name = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mmlflow-tracker-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcreate_date\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m Tracker.create(display_name=tracker_name) \u001b[34mas\u001b[39;49;00m tracker:\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_parameters(tracker_parameters)\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_parameters(r.data.params)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMetric cannot be logged when creating a tracker in this way\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m artifact \u001b[35min\u001b[39;49;00m artifacts:\u001b[37m\u001b[39;49;00m\n",
      "                tracker.log_output(name=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMLFlow.\u001b[39;49;00m\u001b[33m{\u001b[39;49;00martifact\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mr.info.artifact_uri\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00martifact\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            tracker.log_output(name=\u001b[33m\"\u001b[39;49;00m\u001b[33mSageMaker.ModelArtifact\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[33m\"\u001b[39;49;00m\u001b[33mNA\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./source_dir/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn container\n",
    "\n",
    "For this example, we use the `SKlearn` framework in script mode with SageMaker. For more information please refere to [the official documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html)\n",
    "\n",
    "Our training script makes use of other 3rd party libraries, i.e. `mlflow`, which are not installed by default in the `Sklearn` container SageMaker provides. However, this can be easily overcome by supplying a `requirement.txt` file in the `source_dir` folder, which then SageMaker will `pip`-install before executing the training script.\n",
    "\n",
    "### Metric definition\n",
    "\n",
    "SageMaker emits every log to CLoudWatch. Since we are using scripting mode, we need to specify a metric definition object to define the format of the metric we are interested in via regex, so that SageMaker knows how to extract this metric from the CloudWatch logs of the training job.\n",
    "\n",
    "In our case our custom metric is as follow\n",
    "\n",
    "```python\n",
    "metric_definitions = [{'Name': 'median-AE', 'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "metric_definitions = [{'Name': 'median-AE', 'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}]\n",
    "\n",
    "hyperparameters = {\n",
    "    'tracking_uri': tracking_uri,\n",
    "    'experiment_name': experiment_name,\n",
    "    'secret_name': mlflow_secret_name,\n",
    "    'region': region,\n",
    "    'n-estimators': 100,\n",
    "    'min-samples-leaf': 3,\n",
    "    'features': 'MedInc HouseAge AveRooms AveBedrms Population AveOccup',\n",
    "    'target': 'target'\n",
    "}\n",
    "\n",
    "estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='source_dir',\n",
    "    role=role,\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',  # to run SageMaker in a managed infrastructure\n",
    "    framework_version='1.0-1',\n",
    "    base_job_name='mlflow',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to execute the training locally, which in turn will save its execution data to the MLFlow server. After initializing an `SKlearn` estimator object, all we need to do is to call the `.fit` method specifying where the training and testing data are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: mlflow-2024-03-13-22-11-45-156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2024-03-13 22:11:45 Starting - Starting the training job...\n",
      "2024-03-13 22:12:01 Starting - Preparing the instances for training...\n",
      "2024-03-13 22:12:37 Downloading - Downloading input data...\n",
      "2024-03-13 22:13:14 Downloading - Downloading the training image......\n",
      "2024-03-13 22:14:14 Training - Training image download completed. Training in progress..\u001b[34m2024-03-13 22:14:16,022 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:16,025 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:16,028 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:16,044 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:16,317 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting mlflow==2.7.1 (from -r requirements.txt (line 1))\n",
      "  Downloading mlflow-2.7.1-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib (from -r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-experiments (from -r requirements.txt (line 3))\n",
      "  Downloading sagemaker_experiments-0.1.45-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting cloudpickle<3 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli<1,>=0.8.7 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints<1 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython<4,>=2.1.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyyaml<7,>=5.1 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5,>=3.12.0 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz<2024 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.17.3 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting packaging<24 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata!=4.7.0,<7,>=3.7.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse<1,>=0.4.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic!=1.10.0,<2 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker<7,>=4.0.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask<3 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas<3 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser<2 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy<3,>=1.4.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading SQLAlchemy-2.0.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<2 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (1.0.2)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow<14,>=4.0.0 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading pyarrow-13.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown<4,>=3.3 (from mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gunicorn<22 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (20.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2<4,>=2.11 in /miniconda3/lib/python3.8/site-packages (from mlflow==2.7.1->-r requirements.txt (line 1)) (3.0.3)\u001b[0m\n",
      "\u001b[34mCollecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.49.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.1/159.1 kB 16.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (10.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=3.2.0 (from matplotlib->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.3.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.16.27 in /miniconda3/lib/python3.8/site-packages (from sagemaker-experiments->-r requirements.txt (line 3)) (1.28.57)\u001b[0m\n",
      "\u001b[34mCollecting Mako (from alembic!=1.10.0,<2->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions>=4 (from alembic!=1.10.0,<2->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.32.0,>=1.31.57 in /miniconda3/lib/python3.8/site-packages (from boto3>=1.16.27->sagemaker-experiments->-r requirements.txt (line 3)) (1.31.85)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3>=1.16.27->sagemaker-experiments->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /miniconda3/lib/python3.8/site-packages (from boto3>=1.16.27->sagemaker-experiments->-r requirements.txt (line 3)) (0.7.0)\u001b[0m\n",
      "\u001b[34mCollecting pyjwt>=1.7.0 (from databricks-cli<1,>=0.8.7->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.1.0 (from databricks-cli<1,>=0.8.7->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting tabulate>=0.7.7 (from databricks-cli<1,>=0.8.7->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /miniconda3/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.26.7 in /miniconda3/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1->-r requirements.txt (line 1)) (1.26.18)\u001b[0m\n",
      "\u001b[34mCollecting websocket-client>=0.32.0 (from docker<7,>=4.0.0->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=0.15 in /miniconda3/lib/python3.8/site-packages (from Flask<3->mlflow==2.7.1->-r requirements.txt (line 1)) (0.15.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=0.24 in /miniconda3/lib/python3.8/site-packages (from Flask<3->mlflow==2.7.1->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=3.0 in /miniconda3/lib/python3.8/site-packages (from gunicorn<22->mlflow==2.7.1->-r requirements.txt (line 1)) (65.5.1)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5 (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading zipp-3.18.0-py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /miniconda3/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow==2.7.1->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow==2.7.1->-r requirements.txt (line 1)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.8/site-packages (from scikit-learn<2->mlflow==2.7.1->-r requirements.txt (line 1)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn<2->mlflow==2.7.1->-r requirements.txt (line 1)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /miniconda3/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.7.1->-r requirements.txt (line 1)) (3.0.1)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.7.1->-r requirements.txt (line 1))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.7.1-py3-none-any.whl (18.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.5/18.5 MB 83.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\u001b[0m\n",
      "\u001b[34m   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 116.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_experiments-0.1.45-py3-none-any.whl (42 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 kB 7.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.4/233.4 kB 39.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.1/301.1 kB 42.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.3/150.3 kB 27.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.1/148.1 kB 19.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading fonttools-4.49.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 117.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 195.4/195.4 kB 29.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.3.0-py3-none-any.whl (35 kB)\u001b[0m\n",
      "\u001b[34mDownloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 84.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.9/103.9 kB 22.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 11.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow-13.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.1/40.1 MB 56.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.2/103.2 kB 14.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 736.6/736.6 kB 75.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 118.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 8.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 1.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\u001b[0m\n",
      "\u001b[34mDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\u001b[0m\n",
      "\u001b[34mDownloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.5/58.5 kB 12.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.18.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 16.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker-example\n",
      "  Building wheel for sagemaker-example (setup.py): started\n",
      "  Building wheel for sagemaker-example (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-example: filename=sagemaker_example-1.0-py3-none-any.whl size=1068 sha256=6c42dac72b3f46aa3a3eee20314b2dbb6738f1a7e12a20cf4def8e086b75f28e\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-6eo49fok/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker-example\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sagemaker-example, zipp, websocket-client, typing-extensions, tabulate, sqlparse, smmap, querystring-parser, pyyaml, pyparsing, pyjwt, pyarrow, packaging, oauthlib, Mako, kiwisolver, fonttools, entrypoints, cycler, contourpy, cloudpickle, sqlalchemy, importlib-resources, importlib-metadata, gitdb, docker, databricks-cli, matplotlib, markdown, gitpython, alembic, mlflow, sagemaker-experiments\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.1\n",
      "    Uninstalling pyarrow-14.0.1:\n",
      "      Successfully uninstalled pyarrow-14.0.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.3.2 alembic-1.13.1 cloudpickle-2.2.1 contourpy-1.1.1 cycler-0.12.1 databricks-cli-0.18.0 docker-6.1.3 entrypoints-0.4 fonttools-4.49.0 gitdb-4.0.11 gitpython-3.1.42 importlib-metadata-6.11.0 importlib-resources-6.3.0 kiwisolver-1.4.5 markdown-3.5.2 matplotlib-3.7.5 mlflow-2.7.1 oauthlib-3.2.2 packaging-23.2 pyarrow-13.0.0 pyjwt-2.8.0 pyparsing-3.1.2 pyyaml-6.0.1 querystring-parser-1.2.4 sagemaker-example-1.0 sagemaker-experiments-0.1.45 smmap-5.0.1 sqlalchemy-2.0.28 sqlparse-0.4.4 tabulate-0.9.0 typing-extensions-4.10.0 websocket-client-1.7.0 zipp-3.18.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,133 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,136 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,154 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,157 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,177 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,179 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,195 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"experiment_name\": \"DEMO-sagemaker-mlflow\",\n",
      "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup\",\n",
      "        \"min-samples-leaf\": 3,\n",
      "        \"n-estimators\": 100,\n",
      "        \"region\": \"us-east-1\",\n",
      "        \"secret_name\": \"mlflow-server-credentials\",\n",
      "        \"target\": \"target\",\n",
      "        \"tracking_uri\": \"https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"mlflow-2024-03-13-22-11-45-156\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-664947382407/mlflow-2024-03-13-22-11-45-156/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"experiment_name\":\"DEMO-sagemaker-mlflow\",\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup\",\"min-samples-leaf\":3,\"n-estimators\":100,\"region\":\"us-east-1\",\"secret_name\":\"mlflow-server-credentials\",\"target\":\"target\",\"tracking_uri\":\"https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-664947382407/mlflow-2024-03-13-22-11-45-156/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"experiment_name\":\"DEMO-sagemaker-mlflow\",\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup\",\"min-samples-leaf\":3,\"n-estimators\":100,\"region\":\"us-east-1\",\"secret_name\":\"mlflow-server-credentials\",\"target\":\"target\",\"tracking_uri\":\"https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"mlflow-2024-03-13-22-11-45-156\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-664947382407/mlflow-2024-03-13-22-11-45-156/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--experiment_name\",\"DEMO-sagemaker-mlflow\",\"--features\",\"MedInc HouseAge AveRooms AveBedrms Population AveOccup\",\"--min-samples-leaf\",\"3\",\"--n-estimators\",\"100\",\"--region\",\"us-east-1\",\"--secret_name\",\"mlflow-server-credentials\",\"--target\",\"target\",\"--tracking_uri\",\"https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=DEMO-sagemaker-mlflow\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=MedInc HouseAge AveRooms AveBedrms Population AveOccup\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_REGION=us-east-1\u001b[0m\n",
      "\u001b[34mSM_HP_SECRET_NAME=mlflow-server-credentials\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=target\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train --experiment_name DEMO-sagemaker-mlflow --features MedInc HouseAge AveRooms AveBedrms Population AveOccup --min-samples-leaf 3 --n-estimators 100 --region us-east-1 --secret_name mlflow-server-credentials --target target --tracking_uri https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,198 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-03-13 22:14:29,198 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mINFO:root:reading data\u001b[0m\n",
      "\u001b[34mINFO:root:building training and testing datasets\u001b[0m\n",
      "\u001b[34m2024/03/13 22:15:03 INFO mlflow.tracking.fluent: Experiment with name 'DEMO-sagemaker-mlflow' does not exist. Creating a new experiment.\u001b[0m\n",
      "\u001b[34m2024/03/13 22:15:04 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\u001b[0m\n",
      "\u001b[34mINFO:root:training model\u001b[0m\n",
      "\u001b[34m2024/03/13 22:15:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/miniconda3/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\u001b[0m\n",
      "\u001b[34mINFO:root:evaluating model\u001b[0m\n",
      "\u001b[34mINFO:root:AE-at-10th-percentile: 0.05450197390151492\u001b[0m\n",
      "\u001b[34mINFO:root:AE-at-50th-percentile: 0.32750396129870146\u001b[0m\n",
      "\u001b[34mINFO:root:AE-at-90th-percentile: 1.008403288039683\u001b[0m\n",
      "\u001b[34mINFO:root:saving model in MLflow\u001b[0m\n",
      "\u001b[34mrun_id: 57a1f126002344d2bad7ded0eaf684d6\u001b[0m\n",
      "\u001b[34martifacts: ['model/MLmodel', 'model/conda.yaml', 'model/model.pkl', 'model/python_env.yaml', 'model/requirements.txt']\u001b[0m\n",
      "\u001b[34mparams: {'bootstrap': 'True', 'ccp_alpha': '0.0', 'criterion': 'squared_error', 'features': 'MedInc HouseAge AveRooms AveBedrms Population AveOccup', 'max_depth': 'None', 'max_features': 'auto', 'max_leaf_nodes': 'None', 'max_samples': 'None', 'min-samples-leaf': '3', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '3', 'min_samples_split': '2', 'min_weight_fraction_leaf': '0.0', 'n-estimators': '100', 'n_estimators': '100', 'n_jobs': '-1', 'oob_score': 'False', 'random_state': 'None', 'verbose': '0', 'warm_start': 'False'}\u001b[0m\n",
      "\u001b[34mmetrics: {'AE-at-10th-percentile': 0.05450197390151492, 'AE-at-50th-percentile': 0.32750396129870146, 'AE-at-90th-percentile': 1.008403288039683, 'training_mean_absolute_error': 0.24639977920703307, 'training_mean_squared_error': 0.1320964363315481, 'training_r2_score': 0.9010005515399621, 'training_root_mean_squared_error': 0.363450734394014, 'training_score': 0.9010005515399621}\u001b[0m\n",
      "\u001b[34mLoaded existing tracker\u001b[0m\n",
      "\u001b[34m2024-03-13 22:15:18,672 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-13 22:15:36 Uploading - Uploading generated training model\n",
      "2024-03-13 22:15:36 Completed - Training job completed\n",
      "Training seconds: 183\n",
      "Billable seconds: 183\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':train_path, 'test': test_path}, experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From SageMaker to MLFlow\n",
    "\n",
    "Load the <i>TrialComponent</i> associate with the `estimator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "\n",
    "trial_component = TrialComponent.load(f\"{training_job_name}-aws-training-job\")\n",
    "mlflow_run_url = trial_component.parameters[\"mlflow-run-url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=https://bsv9uzt1l6.execute-api.us-east-1.amazonaws.com/#/experiments/1/runs/57a1f126002344d2bad7ded0eaf684d6>link to MLFlow run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<a href={}>link to MLFlow run</a>\".format(mlflow_run_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From MLFlow to SageMaker Experiments\n",
    "\n",
    "Within SageMaker Experiments, we have enriched the <i>TrialComponent</i> with information specific to MLFlow. For example\n",
    "\n",
    "* the experiment ID in MLFlow\n",
    "* the MLFlow run ID corresponding to the SageMaker training job\n",
    "* any additional MLFlow parameters and metrics generated by MLFlow\n",
    "* the list of output artifacts generated by MLFlow (e.g., the output model) with their full path to S3\n",
    "\n",
    "A visual inspection of the SageMaker Studio UI for the output artifacts can be seen below\n",
    "\n",
    "![MLFlow Output Artifacts in SageMaker Experiments](./../../images/trialcomponent-output-artifacts-mlflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model to MLFlow\n",
    "\n",
    "At the end of the training, our model has been saved to the MLflow server and we are ready to register the model, i.e. assign it to a model package and create a version. Please refer to the [official MLFlow documentation](https://www.mlflow.org/docs/latest/model-registry.html) for furthe information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_credentials(region_name, secret_name):\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    \n",
    "    kwarg = {'SecretId': secret_name}\n",
    "    secret = client.get_secret_value(**kwarg)\n",
    "    credentials = {}\n",
    "\n",
    "    credentials['username'] = json.loads(secret['SecretString'])['username']\n",
    "    credentials['password'] = json.loads(secret['SecretString'])['password']\n",
    "    \n",
    "    return credentials\n",
    "\n",
    "# set the tracking token env variable will enable the mlflow SDK to set the header \"Authentication: Basic <credentials>\" to authenticate.\n",
    "credentials = retrieve_credentials(region, mlflow_secret_name)\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = credentials['username']\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = credentials['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/13 22:16:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: california-housing-model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_version: <ModelVersion: aliases=[], creation_timestamp=1710368197735, current_stage='None', description='', last_updated_timestamp=1710368197735, name='california-housing-model', run_id='57a1f126002344d2bad7ded0eaf684d6', run_link='', source='s3://mlflow-664947382407-us-east-1/1/57a1f126002344d2bad7ded0eaf684d6/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = MlflowClient()\n",
    "\n",
    "run = mlflow.get_run(run_id=trial_component.parameters[\"run_id\"])\n",
    "\n",
    "try:\n",
    "    client.create_registered_model(model_name)\n",
    "except:\n",
    "    print(\"Registered model already exists\")\n",
    "\n",
    "model_version = client.create_model_version(\n",
    "    name=model_name,\n",
    "    source=\"{}/model\".format(run.info.artifact_uri),\n",
    "    run_id=run.info.run_uuid\n",
    ")\n",
    "\n",
    "print(\"model_version: {}\".format(model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Predictions\n",
    "\n",
    "We are now ready to make predictions with our model locally for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URI: s3://mlflow-664947382407-us-east-1/1/57a1f126002344d2bad7ded0eaf684d6/artifacts/model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc47bb89ac4427bbe6c2770e1ecf6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_fit_context' from 'sklearn.base' (/opt/conda/lib/python3.10/site-packages/sklearn/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel URI: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_uri))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load model as a Sklearn model.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# get a random index to test the prediction from the test data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(testX))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:615\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path)\u001b[0m\n\u001b[1;32m    613\u001b[0m sklearn_model_artifacts_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_model_path, flavor_conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickled_model\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    614\u001b[0m serialization_format \u001b[38;5;241m=\u001b[39m flavor_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, SERIALIZATION_FORMAT_PICKLE)\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_local_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msklearn_model_artifacts_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:451\u001b[0m, in \u001b[0;36m_load_model_from_local_file\u001b[0;34m(path, serialization_format)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m serialization_format \u001b[38;5;241m==\u001b[39m SERIALIZATION_FORMAT_CLOUDPICKLE:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudpickle\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.ensemble` module includes ensemble-based methods for\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclassification, regression and anomaly detection.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaggingClassifier, BaggingRegressor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     ExtraTreesClassifier,\n\u001b[1;32m      9\u001b[0m     ExtraTreesRegressor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     RandomTreesEmbedding,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierMixin, RegressorMixin, _fit_context\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, r2_score\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier, DecisionTreeRegressor\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_fit_context' from 'sklearn.base' (/opt/conda/lib/python3.10/site-packages/sklearn/base.py)"
     ]
    }
   ],
   "source": [
    "# get the model URI from the MLFlow registry\n",
    "model_uri = model_version.source\n",
    "print(\"Model URI: {}\".format(model_uri))\n",
    "\n",
    "# Load model as a Sklearn model.\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# get a random index to test the prediction from the test data\n",
    "index = random.randrange(0, len(testX))\n",
    "print(\"Random index value: {}\".format(index))\n",
    "\n",
    "# Prepare data on a Pandas DataFrame to make a prediction.\n",
    "data = testX.drop(['Latitude','Longitude','target'], axis=1).iloc[[index]]\n",
    "\n",
    "print(\"#######\\nData for prediction \\n{}\".format(data))\n",
    "\n",
    "y_hat = loaded_model.predict(data)[0]\n",
    "y = y_test[index]\n",
    "\n",
    "print(\"Predicted value: {}\".format(y_hat))\n",
    "print(\"Actual value: {}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune a Scikit-Learn model in SageMaker and track with MLFlow\n",
    "\n",
    "At this point, we are going to offload the training to the remote infrastructure managed by SageMaker. We want now to leverage SageMaker's hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations, to find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large impact on model accuracy. In this example, we'll use the SageMaker Python SDK to create a hyperparameter tuning job for an SKlearn estimator.\n",
    "\n",
    "## Training\n",
    "We are again using `SKlearn` in script mode, with the same training script we have used in the previous section, i.e. `./source_dir/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'tracking_uri': tracking_uri,\n",
    "    'experiment_name': experiment_name,\n",
    "    'secret_name': mlflow_secret_name,\n",
    "    'region': region,\n",
    "    'features': 'MedInc HouseAge AveRooms AveBedrms Population AveOccup',\n",
    "    'target': 'target'\n",
    "}\n",
    "\n",
    "metric_definitions = [{'Name': 'median-AE', 'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}]\n",
    "\n",
    "estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='source_dir',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    framework_version='1.0-1',\n",
    "    py_version='py3'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Once we've defined our estimator we can specify the hyperparameters we'd like to tune and their possible values.  We have three different types of hyperparameters.\n",
    "- Categorical parameters need to take one value from a discrete set.  We define this by passing the list of possible values to `CategoricalParameter(list)`\n",
    "- Continuous parameters can take any real number value between the minimum and maximum value, defined by `ContinuousParameter(min, max)`\n",
    "- Integer parameters can take any integer value between the minimum and maximum value, defined by `IntegerParameter(min, max)`\n",
    "\n",
    "*Note, if possible, it's almost always best to specify a value as the least restrictive type.  For example, tuning `thresh` as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with possible values of 0.01, 0.1, 0.15, or 0.2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'n-estimators': IntegerParameter(50, 200),\n",
    "    'min-samples-leaf': IntegerParameter(1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition. This refers to the regular expression (Regex) needed to extract that metric from the CloudWatch logs of our training job we defined earlier, as well as whether we are looking to `Maximize` or `Minimize` the objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'median-AE'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a `HyperparameterTuner` object, which we pass:\n",
    "- The SKLearn estimator we created earlier\n",
    "- Our hyperparameter ranges\n",
    "- Objective metric name and type\n",
    "- Number of training jobs to run in total and how many training jobs should be run simultaneously.  More parallel jobs will finish tuning sooner, but may sacrifice accuracy.  We recommend you set the parallel jobs value to less than 10% of the total number of training jobs (we'll set it higher just for this example to keep it short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jobs = 5\n",
    "max_parallel_jobs = 5\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=max_jobs,\n",
    "                            max_parallel_jobs=max_parallel_jobs,\n",
    "                            objective_type=objective_type,\n",
    "                            base_tuning_job_name='mlflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can start our tuning job by calling `.fit()` and passing in the S3 paths to our train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train':train_path, 'test': test_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the MLFlow server to see the different models and their metrics that have been stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy an MLflow model with SageMaker\n",
    "\n",
    "We are finally ready to deploy a MLFlow model to a SageMaker hosted endpoint ready to be consumed for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MLflow docker image to serve the model with SageMaker\n",
    "\n",
    "We first need to build a new MLflow Sagemaker image, assign it a name, and push to ECR.\n",
    "\n",
    "The `mlflow sagemaker build-and-push-container` function does exactly that. It first builds an MLflow Docker image. The image is built locally and it requires Docker to run. Then, the image is pushed to ECR under current active AWS account and to current active AWS region. More information on this command can be found in the official [MLflow CLI documentation for SageMaker](https://www.mlflow.org/docs/latest/cli.html#mlflow-sagemaker).\n",
    "\n",
    "Make sure that you the `mlflow-pyfunc` container has already been pushed to `ECR` from the `Cloud9` environment from where deployed the CDK stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the ECR-hosted Docker image the model should be deployed into: make sure to include the tag 2.7.1\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/mlflow-pyfunc:{}\".format(account, region, mlflow.__version__)\n",
    "print(\"image URI: {}\".format(image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a SageMaker endpoint with our scikit-learn model\n",
    "\n",
    "We first need to get the best performing model stored in MLFlow. Once it has been identified, we register it to the Registry and then deploy to a SageMaker managed endpoint via the MLflow SDK. More information can be found [here](https://www.mlflow.org/docs/latest/python_api/mlflow.sagemaker.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training_job_name = tuner.best_training_job()\n",
    "\n",
    "best_trial_component = TrialComponent.load(f\"{best_training_job_name}-aws-training-job\")\n",
    "best_mlflow_run_url = best_trial_component.parameters[\"mlflow-run-url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<a href={}>MLFlow run corresponding to best training job</a>\".format(best_mlflow_run_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "run = mlflow.get_run(run_id=best_trial_component.parameters[\"run_id\"])\n",
    "\n",
    "try:\n",
    "    client.create_registered_model(model_name)\n",
    "except:\n",
    "    print(\"Registered model already exists\")\n",
    "\n",
    "model_version = client.create_model_version(\n",
    "    name=model_name,\n",
    "    source=\"{}/model\".format(run.info.artifact_uri),\n",
    "    run_id=run.info.run_uuid\n",
    ")\n",
    "\n",
    "print(\"model_version: {}\".format(model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "model_uri = \"models:/{}/{}\".format(model_version.name, model_version.version)\n",
    "\n",
    "endpoint_name = 'california-housing'\n",
    "\n",
    "config={\n",
    "    'execution_role_arn': role,\n",
    "    'image_url': image_uri,\n",
    "    'instance_type': 'ml.m5.xlarge',\n",
    "    'instance_count': 1,\n",
    "    'region_name': region\n",
    "}\n",
    "\n",
    "client = get_deploy_client(\"sagemaker\")\n",
    "\n",
    "client.create_deployment(\n",
    "    name=endpoint_name,\n",
    "    model_uri=model_uri,\n",
    "    flavor='python_function',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "We are now ready to make predictions again the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load california  dataset\n",
    "data = pd.read_csv('./california_test.csv')\n",
    "df_y = data[['target']]\n",
    "df = data.drop(['Latitude','Longitude','target'], axis=1)\n",
    "\n",
    "client = get_deploy_client(f\"sagemaker:/{region}\")\n",
    "\n",
    "for _ in range(0,2):\n",
    "    # Randomly pick a row to test the prediction\n",
    "    index = random.randrange(0, len(df_y))\n",
    "    payload = df.iloc[[index]]\n",
    "    y = df_y['target'][index]\n",
    "    print(f\"payload: {payload}\")\n",
    "    prediction = client.predict(endpoint_name, payload)\n",
    "    print(f'This is the real value of the housing we want to predict (expressed in 100.000$): {y}')\n",
    "    print(f\"This is the predicted value from our model (expressed in 100.000$): {prediction['predictions'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint\n",
    "\n",
    "In order to avoid unwanted costs, make sure you delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_deployment(endpoint_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete experiments (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment.delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "04ffa0b675ec4736afd1210dd81a6f70b0b4fa83298b056bd6b4e16ede0b389c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
